{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Deep Learning using Pytorch\n",
    "\n",
    "Explains Tensors, Automatic Gradients, Neural Networks and Optimisers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "#### Making Tensors\n",
    "\n",
    "Check out this [link](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html) for more information on Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero tensor \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "One tensor \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Normally distributed Random tensor \n",
      " tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "print(\"Zero tensor \\n\",zeros)\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "print(\"One tensor \\n\",ones)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2, 3)\n",
    "print(\"Normally distributed Random tensor \\n\",random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Shapes and Types\n",
    "\n",
    "Often in DL, the first index is the Batch number, and rest are dimensions \n",
    "\n",
    "Eg for Images\n",
    "(batch_size, channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[3, 3, 2],\n",
      "        [1, 4, 0]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "\n",
    "some_constants = torch.tensor([[3.14,3, 2.71], [1.61,4, 0.007]],  dtype=torch.int16)\n",
    "print(some_constants.shape)\n",
    "print(some_constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Broadcasting\n",
    "\n",
    "Very similar to numpy broadcasting, here we will show multiplications, using tensors.\n",
    "Both @ and torch.matmul do same matrix multiplication, but @ can do broadcasting implicitly, while torch.matmul cannot.\n",
    "@ will broadcast the smaller tensor to match the shape of the larger one, and do the multiplication.\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0310, -0.1537,  0.8066],\n",
      "        [-0.3339, -1.0741, -0.5760]])\n",
      "tensor([[0.3243, 1.3390]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 1x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[0;32m----> 6\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape, b\u001b[38;5;241m.\u001b[39mshape, c\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 1x2)"
     ]
    }
   ],
   "source": [
    "# Showing torch @\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(1, 2)\n",
    "print(b)\n",
    "c = a @ b\n",
    "print(c)\n",
    "print(a.shape, b.shape, c.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving to GPUs\n",
    "\n",
    "By default, new tensors are created on the CPU, so we have to specify when we want to create our tensor on the GPU with the optional device argument. You can see when we print the new tensor, PyTorch informs us which device it’s on (if it’s not on CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "tensor([[0.9413, 0.4460],\n",
      "        [0.9289, 0.6293]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "print('Device: {}'.format(my_device))\n",
    "\n",
    "x = torch.rand(2, 2, device=my_device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Tensor Shapes\n",
    "\n",
    "For a model that works on 3 x 226 x 226 images - a 226-pixel square with 3 color channels. When you load and transform it, you’ll get a tensor of shape (3, 226, 226). Your model, though, is expecting input of shape (N, 3, 226, 226), where N is the number of images in the batch. We unqueeze the tensor to add a dimension at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 226, 226)\n",
    "b = a.unsqueeze(0)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsqueeze is a way to add a dimension to a tensor, and squeeze is a way to remove a dimension of extent 1, to do unbatched computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[0.6191, 0.9935, 0.1844, 0.6138, 0.6854, 0.0438, 0.0636, 0.2884, 0.4362,\n",
      "         0.2368, 0.1394, 0.1721, 0.1751, 0.3851, 0.0732, 0.3118, 0.9180, 0.7293,\n",
      "         0.5351, 0.5078]])\n",
      "torch.Size([20])\n",
      "tensor([0.6191, 0.9935, 0.1844, 0.6138, 0.6854, 0.0438, 0.0636, 0.2884, 0.4362,\n",
      "        0.2368, 0.1394, 0.1721, 0.1751, 0.3851, 0.0732, 0.3118, 0.9180, 0.7293,\n",
      "        0.5351, 0.5078])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 20)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "b = a.squeeze(0)\n",
    "print(b.shape)\n",
    "print(b)\n",
    "\n",
    "# Will not be squeezed\n",
    "c = torch.rand(2, 2)\n",
    "print(c.shape)\n",
    "\n",
    "d = c.squeeze(0)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 20])\n",
      "torch.Size([1, 2400])\n",
      "torch.Size([1200, 2])\n"
     ]
    }
   ],
   "source": [
    "output3d = torch.rand(6, 20, 20)\n",
    "print(output3d.shape)\n",
    "\n",
    "input1d = output3d.reshape(1, 6 * 20 * 20)\n",
    "print(input1d.shape)\n",
    "\n",
    "input1d = output3d.reshape(-1, 2)\n",
    "print(input1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the order of the 1200,2 tensor datas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Gradients\n",
    "\n",
    "I hope you know what autograd is why we are using it, if not then check out this [link](https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html) for more information on Automatic Gradients. \n",
    "\n",
    "Here we will foucs on the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x10dd0f640>\n",
      "Gradient function for loss = <MulBackward0 object at 0x11ae0c940>\n",
      "tensor([[ 2.0819,  4.3074, -3.6664],\n",
      "        [ 2.0819,  4.3074, -3.6664],\n",
      "        [ 2.0819,  4.3074, -3.6664],\n",
      "        [ 2.0819,  4.3074, -3.6664],\n",
      "        [ 2.0819,  4.3074, -3.6664]])\n",
      "tensor([ 2.0819,  4.3074, -3.6664])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Input tensor\n",
    "x = torch.ones(5)  \n",
    "# Expected output\n",
    "y = torch.zeros(3)\n",
    "\n",
    "# Parameters to get the gradients for\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "# loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss = 0.5*(z - y).pow(2).sum()\n",
    "\n",
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)\n",
    "\n",
    "# The backward() call will compute the gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd also makes a Handy profiler and has Higher level APIs for computing jacobiens, hessians etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Making simple Neural Networks using Pytorch\n",
    "\n",
    "More info at this [link](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Multi Layer Perceptron\n",
    "\n",
    "The NN layers have some default intialisation, but you can also specify your own initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        # Initialize the superclass and store the parameters\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        # Define the layers of the model\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        # Initialize layers using Xavier initialization\n",
    "        init.xavier_normal_(self.linear1.weight)\n",
    "        init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This function defines the forward pass of the model\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "tinymodel = TinyModel(input_size = 100, output_size = 10, hidden_size = 50)\n",
    "\n",
    "# Checking the Model\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\nJust one layer:')\n",
    "print(tinymodel.linear2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are checking the summary for an input to the model. Note the input is (5,100), where 5 is the batch size and 100 is the input size, while we have not specified the batch size in the model, we do not have to, torch.nn takes care of it, we write the model as if only 1 data point is being passed through it.\n",
    "\n",
    "### Important question, batch sizes and batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 50]           5,050\n",
      "              ReLU-2                   [-1, 50]               0\n",
      "            Linear-3                   [-1, 10]             510\n",
      "           Softmax-4                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 5,560\n",
      "Trainable params: 5,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(tinymodel, (100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A convolutional Neural Network\n",
    "\n",
    "The model takes black and white images so in_channels = 1. For colored images, in_channels = 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # The input to the network is of shape (28,28,1)\n",
    "        # Should it not be of shape (1,28,28)? or (batch, channels, height, width) ??\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.out = nn.Linear(2048,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Convolve, relu, max pool\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Convolve, relu, max pool\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Flatten the tensor, The size of the tensor is (batch_size, 32, 8, 8) 32*8*8 = 2048\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, here we not giving the batch size like (10,1,32,32), and it is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             416\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]          12,832\n",
      "              ReLU-5           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
      "            Linear-7                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 33,738\n",
      "Trainable params: 33,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.42\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.55\n",
      "----------------------------------------------------------------\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "cnn = CNN()\n",
    "summary(cnn, (1 ,32, 32))\n",
    "\n",
    "input_data = torch.rand(10, 1, 32, 32)\n",
    "print(cnn(input_data).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can make other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisers\n",
    "\n",
    "Here, we will show how to use Optimiser to train your network or model (and Learning Rate schedulers). \n",
    "\n",
    "For further info into Optimisers, check out this [link](https://pytorch.org/docs/stable/optim.html),\n",
    "and for Learning Rate Schedulers, check out this [link](https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are training a simple MLP on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2009700.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:01<00:00, 22596.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3301511.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1295778.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "\n",
    "first_batch = next(iter(train_loader))\n",
    "print(first_batch[0].shape, first_batch[1].shape)\n",
    "# Shape of X and y of first batch, 600 such batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]          78,500\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "            Linear-3                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Checking the Model\n",
    "summary(model, (28*28,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1) Load images as Variable\n",
    "2) Apply forward pass and get model outputs.\n",
    "3) Make a Loss tensor form the Loss of output vs true labels\n",
    "4) Use loss.backward() to compute the gradients of all parameters of the model, as all have _grad = True, \n",
    "5) Using optimizer.step() after that changes the values of all the parameters put in the optimiser using the gradients based on the Optimiser's algorithm.\n",
    "6) Zero the gradients, as Pytorch accumulates gradients, and we do not want to use the old gradients again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Using the Optimiser to backpropagate the model\n",
    "learning_rate = 0.1\n",
    "model = Model(input_dim, hidden_dim, output_dim)\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def process(optimizer):\n",
    "  iter = 0\n",
    "  for epoch in range(num_epochs):\n",
    "      for i, (images, labels) in enumerate(train_loader):\n",
    "          images = images.view(-1, 28*28).requires_grad_() # 1)\n",
    "          outputs = model(images)                          # 2) \n",
    "\n",
    "          loss = criterion(outputs, labels)               # 3)  \n",
    "\n",
    "          loss.backward()                                 # 4)\n",
    "          optimizer.step()                                # 5)\n",
    "\n",
    "          optimizer.zero_grad()                          # 6)\n",
    "          iter += 1\n",
    "\n",
    "        ### This part is for printing the loss and accuracy\n",
    "          if iter % 500 == 0:\n",
    "              correct = 0 ; total = 0\n",
    "              for images, labels in test_loader:\n",
    "                  images = images.view(-1, 28*28)\n",
    "                  outputs = model(images)\n",
    "                  _, predicted = torch.max(outputs.data, 1)\n",
    "                  total += labels.size(0)\n",
    "                  correct += (predicted == labels).sum()\n",
    "              accuracy = 100 * correct / total\n",
    "              \n",
    "              print('Iteration: {}. Loss: {:.3f}. Accuracy: {:.3f}'.format(iter, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.364. Accuracy: 91.420\n",
      "Iteration: 1000. Loss: 0.314. Accuracy: 92.560\n",
      "Iteration: 1500. Loss: 0.275. Accuracy: 93.820\n",
      "Iteration: 2000. Loss: 0.152. Accuracy: 94.490\n",
      "Iteration: 2500. Loss: 0.257. Accuracy: 94.990\n",
      "Iteration: 3000. Loss: 0.101. Accuracy: 95.590\n"
     ]
    }
   ],
   "source": [
    "# Using the Optimiser to backpropagate the model\n",
    "learning_rate = 0.1\n",
    "model = Model(input_dim, hidden_dim, output_dim)\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "process(optimizer_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
